# code_generator_plugin
本插件旨在为MaiBot QQ机器人提供代码生成和执行的能力。通过集成大型语言模型（LLM），机器人可以根据用户提供的自然语言提示词生成Python代码，并在安全的沙箱环境中执行，然后将执行结果返回给用户。这使得机器人能够自主完成一些编程任务，例如数据处理、简单计算等。
## 1. 插件类型选择

考虑到“让机器人自己写代码”的功能，机器人需要能够接收用户的指令，然后根据指令生成并执行代码。MaiBot框架提供了`Action`和`Command`两种组件类型：

*   **Command**: 直接响应用户明确的指令，通过正则表达式匹配用户输入。这适用于用户明确发出“生成代码”指令的场景。
*   **Action**: 由MaiBot的决策系统智能选择是否使用，具有随机性和拟人化。这适用于机器人根据聊天情境自主决定生成代码的场景。

为了实现“机器人自己写代码”的核心功能，并提供明确的触发方式，我们将主要使用**Command**组件来接收用户的代码生成指令。同时，可以考虑结合**Action**组件，在特定对话情境下（例如用户提出需要解决某个问题时），智能地建议或触发代码生成。

## 2. 核心功能与流程

代码生成插件的核心功能是接收用户指令，利用LLM生成Python代码，并在沙箱环境中执行，然后将执行结果返回给用户。

**核心流程如下：**

1.  **指令接收**: 用户通过特定的Command（例如`/generate_code <prompt>`）向机器人发送代码生成请求，其中`<prompt>`是用户对所需代码的描述。
2.  **LLM调用**: 插件接收到指令后，调用MaiBot内置的LLM API (`llm_api.generate_with_model`)，将用户提供的`<prompt>`作为提示词，请求LLM生成Python代码。
3.  **代码执行**: LLM返回生成的Python代码后，插件需要在一个安全的沙箱环境中执行这段代码。为了安全性，我们将使用Python的`exec`函数，并限制其可访问的全局和局部变量，以防止恶意代码执行。
4.  **结果返回**: 代码执行完成后，将执行结果（包括标准输出、错误信息等）捕获并格式化，然后通过MaiBot的消息发送API (`self.send_text`) 返回给用户。

## 3. 插件组件构成

### 3.1 `CodeGeneratorCommand` (Command组件)

*   **职责**: 负责接收用户输入的代码生成指令，解析指令中的提示词，并触发代码生成和执行流程。
*   **`command_name`**: 例如 `generate_code`。
*   **`command_pattern`**: 正则表达式，用于匹配用户输入的指令，并捕获提示词。例如 `r"^/generate_code\s+(?P<prompt>.+)$"`。
*   **`execute`方法**: 
    *   获取用户输入的`prompt`。
    *   调用LLM生成代码。
    *   调用代码执行模块执行代码。
    *   将执行结果通过`self.send_text`发送给用户。

### 3.2 代码执行模块 (内部函数或类)

*   **职责**: 负责安全地执行LLM生成的Python代码，并捕获其输出和错误。
*   **安全性**: 限制`exec`函数的`globals`和`locals`参数，只允许访问必要的内置函数和模块，防止文件系统操作、网络请求等潜在危险行为。
*   **输出捕获**: 重定向`sys.stdout`和`sys.stderr`，捕获代码执行过程中的打印输出和错误信息。
*   **异常处理**: 捕获代码执行过程中可能发生的异常，并将其作为错误信息返回。

### 3.3 LLM交互 (利用MaiBot内置LLM API)

*   **职责**: 提供与MaiBot内置LLM的接口，用于发送提示词并获取生成的代码。
*   **实现**: 直接调用`src.plugin_system.apis.llm_api.generate_with_model`。

## 4. 配置文件与依赖

*   **`_manifest.json`**: 定义插件的基本信息，如名称、版本、描述等。
*   **`config.toml`**: 插件的配置文件，可以用于配置LLM模型名称、沙箱环境的限制等。
*   **Python依赖**: 插件本身可能不需要额外的Python依赖，但生成的代码可能需要。这需要在执行环境中考虑。

## 5. 安全性考虑

由于插件会执行LLM生成的代码，安全性是至关重要的。以下是需要重点关注的方面：

*   **沙箱环境**: 严格限制代码执行环境的权限，防止对系统造成破坏。`exec`函数的`globals`和`locals`参数是关键。
*   **资源限制**: 考虑限制代码执行的时间、内存等资源，防止无限循环或资源耗尽。
*   **输入验证**: 对用户输入的提示词进行初步验证，虽然LLM会处理大部分，但仍需防止明显的恶意注入。
*   **错误处理**: 完善的错误处理机制，确保即使代码执行失败，机器人也能给出友好的提示，而不是崩溃。

## 6. 潜在的扩展

*   **代码调试**: 允许用户在生成代码后，对代码进行修改和调试。
*   **代码保存**: 将生成的代码保存到文件或数据库中，方便后续查看和复用。
*   **多语言支持**: 扩展代码生成能力，支持生成和执行其他编程语言的代码。
*   **工具调用**: 结合MaiBot的Tool系统，让生成的代码能够调用MaiBot提供的工具，例如发送消息、查询信息等，从而实现更复杂的自动化。

这个架构设计旨在提供一个安全、可扩展且功能强大的代码生成插件。


#### 安装教程

1.  **将插件文件放入MaiBot的`plugins`目录**：
    将`code_generation_plugin`文件夹（包含`_manifest.json`和`plugin.py`文件）复制到MaiBot项目的`plugins`目录下。

    ```bash
    cp -r code_generation_plugin /path/to/MaiBot/plugins/
    ```

2.  **配置MaiBot的`model_config.toml`**：
    确保您的MaiBot `config/model_config.toml`文件中配置了可用的LLM API提供商和模型。本插件依赖于MaiBot的LLM API (`llm_api.generate_with_model`) 来生成代码。您需要配置一个能够生成Python代码的LLM模型。

#### 使用说明

插件提供了一个名为 `/generate_code` 的命令，用于触发代码生成和执行。

**命令格式**：

```
/generate_code <你的代码需求描述>
```

**示例**：

用户向机器人发送消息：

```
/generate_code 编写一个Python函数，计算给定列表中所有偶数的和
```

机器人将回复：

```
正在根据您的提示词生成代码：编写一个Python函数，计算给定列表中所有偶数的和
生成的代码：
```python
def sum_even_numbers(numbers):
    total = 0
    for num in numbers:
        if num % 2 == 0:
            total += num
    return total

print(sum_even_numbers([1, 2, 3, 4, 5, 6]))
```
正在执行...
代码执行成功！
输出：
```
12
```
```
